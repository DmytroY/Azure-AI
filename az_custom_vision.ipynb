{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure custom vision image recognition\n",
    "\n",
    "You can train publish and use your image clasification model in Azure Custom Vision studio https://www.customvision.ai/\n",
    "But also you can use API as below and check all steps in Custom Vision studio in paralel.\n",
    "This lab based on https://learn.microsoft.com/en-us/azure/ai-services/custom-vision-service/quickstarts/image-classification?tabs=windows%2Cvisual-studio&pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-cognitiveservices-vision-customvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZURE_AI_CUSTOM_VISION_ENDPOINT is  https://ai-services84921.cognitiveservices.azure.com/\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import os, time, uuid\n",
    "\n",
    "# Set the values of your computer vision endpoint and computer vision key\n",
    "# as environment variables:\n",
    "try:\n",
    "    endpoint = os.environ[\"AZURE_AI_CUSTOM_VISION_ENDPOINT\"]\n",
    "    key = os.environ[\"AZURE_AI_CUSTOM_VISION_KEY\"]\n",
    "    ai_resource_id = os.environ[\"AZURE_AI_RESOURCE_ID\"]\n",
    "    print(\"AZURE_AI_CUSTOM_VISION_ENDPOINT is \", endpoint)\n",
    "except KeyError:\n",
    "    print(\"Missing endpoint, key or resource id. Set them before running this sample.\")\n",
    "    print(\"Set them before running this sample.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": key})\n",
    "trainer = CustomVisionTrainingClient(endpoint, credentials)\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": key})\n",
    "predictor = CustomVisionPredictionClient(endpoint, prediction_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project...e4b9ded3-5888-4855-b224-65ebb4924667\n"
     ]
    }
   ],
   "source": [
    "publish_iteration_name = \"classifyModel\"\n",
    "\n",
    "# Create a new project\n",
    "print (\"Creating project...\", end=\"\")\n",
    "project_name = uuid.uuid4()\n",
    "print (project_name)\n",
    "project = trainer.create_project(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags for the project\n",
    "orange_tag = trainer.create_tag(project.id, \"orange\")\n",
    "banana_tag = trainer.create_tag(project.id, \"banana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training images path: c:\\DY\\Programming\\Azure-AI\\Azure-AI\\data\\training-images\n",
      "Adding images...\n",
      "Added 29 immages\n"
     ]
    }
   ],
   "source": [
    "# collect and tag images\n",
    "\n",
    "base_image_location = os.path.join (os.getcwd(), \"data\", \"training-images\")\n",
    "print(f\"training images path: {base_image_location}\")\n",
    "print(\"Adding images...\")\n",
    "\n",
    "image_list = []\n",
    "\n",
    "for filename in os.listdir(os.path.join(base_image_location, \"banana\")):\n",
    "  with open(os.path.join (base_image_location, \"banana\", filename), \"rb\") as image_contents:\n",
    "    image_list.append(ImageFileCreateEntry(name=filename, contents=image_contents.read(), tag_ids=[banana_tag.id]))\n",
    "\n",
    "for filename in os.listdir(os.path.join(base_image_location, \"orange\")):\n",
    "  with open(os.path.join (base_image_location, \"orange\", filename), \"rb\") as image_contents:\n",
    "    image_list.append(ImageFileCreateEntry(name=filename, contents=image_contents.read(), tag_ids=[orange_tag.id]))\n",
    "\n",
    "print(f\"Added {len(image_list)} immages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ulpoad collected images\n",
    "upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=image_list))\n",
    "if not upload_result.is_batch_successful:\n",
    "    print(\"Image batch upload failed.\")\n",
    "    for image in upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "    exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Completed\n",
      "Waiting 10 seconds...\n"
     ]
    }
   ],
   "source": [
    "# first iteration of the model\n",
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    print (\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook crashed here, instanses of Project and Itteration lost here,\n",
    "# so for recover process and do not spend money for one more training\n",
    "# I go to https://www.customvision.ai/ take project and iteration IDs and set them manualy\n",
    "class Project:\n",
    "    id = \"7da200e5-e8f6-41b6-8e92-e7b9623a0e06\"\n",
    "project = Project()\n",
    "\n",
    "class Iteration:\n",
    "    id = \"ab0f326e-e953-4f48-a8ff-ba433735bf89\"\n",
    "iteration = Iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Publish trained iteration as prediction model \n",
    "import os\n",
    "\n",
    "prediction_resource_id = os.environ[\"AZURE_AI_RESOURCE_ID\"]\n",
    "publish_iteration_name = \"Iteration 1\"\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\torange: 68.70%\n",
      "\tbanana: 32.40%\n"
     ]
    }
   ],
   "source": [
    "# Use published model for prediction\n",
    "# here I will use an aple image, I suppose it shoud be clasified as \"orange\" with higher probability than \"banana\"\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": key})\n",
    "predictor = CustomVisionPredictionClient(endpoint, prediction_credentials)\n",
    "\n",
    "with open(os.path.join (os.getcwd(), \"data\", \"test-images\",\"1.jpg\"), \"rb\") as image_contents:\n",
    "    results = predictor.classify_image(\n",
    "        project.id, publish_iteration_name, image_contents.read())\n",
    "\n",
    "    # Display the results.\n",
    "    for prediction in results.predictions:\n",
    "        print(\"\\t\" + prediction.tag_name +\n",
    "              \": {0:.2f}%\".format(prediction.probability * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
