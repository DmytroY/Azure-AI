{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, publish and use image detection model with Azure Custom Vision\n",
    "This is first part which describes how to use API for upload taged images to Azure Custom Vision Studio project. Next part (az_image_detection2.ipynb) describes how to use API of trained model for object detection. <br>\n",
    "Based on [this](https://microsoftlearning.github.io/mslearn-ai-vision/Instructions/Exercises/03-custom-vision-object-detection.html) Microsoft learn manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-cognitiveservices-vision-customvision==3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "global training_client\n",
    "global custom_vision_project\n",
    "\n",
    "# Get Configuration Settings from .env file\n",
    "load_dotenv()\n",
    "training_endpoint = os.getenv('TRAINING_ENDPOINT')\n",
    "training_key = os.getenv('TRAINING_KEY')\n",
    "project_id = os.getenv('PROJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate a client for the training API\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "training_client = CustomVisionTrainingClient(training_endpoint, credentials)\n",
    "\n",
    "# Get the Custom Vision project previously created in Cusom Vision studio (https://www.customvision.ai/)\n",
    "custom_vision_project = training_client.get_project(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file:  image11.jpg\n",
      "    adding tag:  orange\n",
      "    adding tag:  banana\n",
      "processing file:  image12.jpg\n",
      "    adding tag:  banana\n",
      "    adding tag:  aple\n",
      "    adding tag:  orange\n",
      "processing file:  image13.jpg\n",
      "    adding tag:  orange\n",
      "    adding tag:  banana\n",
      "processing file:  image14.jpg\n",
      "    adding tag:  aple\n",
      "    adding tag:  banana\n",
      "processing file:  image15.jpg\n",
      "    adding tag:  orange\n",
      "    adding tag:  banana\n",
      "processing file:  image16.jpg\n",
      "    adding tag:  banana\n",
      "    adding tag:  aple\n",
      "processing file:  image17.jpg\n",
      "    adding tag:  banana\n",
      "    adding tag:  aple\n",
      "processing file:  image18.jpg\n",
      "    adding tag:  banana\n",
      "    adding tag:  orange\n",
      "    adding tag:  orange\n",
      "processing file:  image19.jpg\n",
      "    adding tag:  orange\n",
      "processing file:  image20.jpg\n",
      "    adding tag:  orange\n",
      "processing file:  image21.jpg\n",
      "    adding tag:  orange\n",
      "processing file:  image22.jpg\n",
      "    adding tag:  orange\n",
      "processing file:  image23.jpg\n",
      "    adding tag:  orange\n",
      "processing file:  image24.jpg\n",
      "    adding tag:  banana\n",
      "processing file:  image25.jpg\n",
      "    adding tag:  banana\n",
      "processing file:  image26.jpg\n",
      "    adding tag:  banana\n",
      "processing file:  image27.jpg\n",
      "    adding tag:  banana\n",
      "processing file:  image28.jpg\n",
      "    adding tag:  banana\n",
      "processing file:  image29.jpg\n",
      "    adding tag:  aple\n",
      "processing file:  image30.jpg\n",
      "    adding tag:  aple\n",
      "processing file:  image31.jpg\n",
      "    adding tag:  aple\n",
      "processing file:  image32.jpg\n",
      "    adding tag:  aple\n",
      "processing file:  image33.jpg\n",
      "    adding tag:  aple\n"
     ]
    }
   ],
   "source": [
    "# Get the tags defined in the project\n",
    "tags = training_client.get_tags(custom_vision_project.id)\n",
    "\n",
    "# Create a list of images with tagged regions\n",
    "tagged_images_with_regions = []\n",
    "\n",
    "# Get the images and tagged regions from the JSON file\n",
    "url_json = os.path.join (os.getcwd(), \"data\", \"training-images\", \"tagged-images.json\")\n",
    "with open(url_json, 'r') as json_file:\n",
    "    tagged_images = json.load(json_file)\n",
    "    for image in tagged_images['files']:\n",
    "        # Get the filename\n",
    "        file = image['filename']\n",
    "        print(\"processing file: \", file)\n",
    "        # Get the tagged regions\n",
    "        regions = []\n",
    "        for tag in image['tags']:\n",
    "            tag_name = tag['tag']\n",
    "            print(\"    adding tag: \", tag_name)\n",
    "            # Look up the tag ID for this tag name\n",
    "            tag_id = next(t for t in tags if t.name == tag_name).id\n",
    "            # Add a region for this tag using the coordinates and dimensions in the JSON\n",
    "            regions.append(Region(tag_id=tag_id, left=tag['left'],top=tag['top'],width=tag['width'],height=tag['height']))\n",
    "        # Add the image and its regions to the list\n",
    "\n",
    "        url_img = os.path.join (os.getcwd(), \"data\", \"training-images\", file)\n",
    "        with open(url_img, mode=\"rb\") as image_data:\n",
    "            tagged_images_with_regions.append(ImageFileCreateEntry(name=file, contents=image_data.read(), regions=regions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images uploaded.\n"
     ]
    }
   ],
   "source": [
    "# Upload the list of images as a batch\n",
    "upload_result = training_client.create_images_from_files(custom_vision_project.id, ImageFileCreateBatch(images=tagged_images_with_regions))\n",
    "# Check for failure\n",
    "if not upload_result.is_batch_successful:\n",
    "    print(\"Image batch upload failed.\")\n",
    "    for image in upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "else:\n",
    "    print(\"Images uploaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tagged images uploaded to the train project in Cusome Vision studio. <br>\n",
    "Use Cusome Vision studio, train and publish model.\n",
    "With next step we will use our trained model for image classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
